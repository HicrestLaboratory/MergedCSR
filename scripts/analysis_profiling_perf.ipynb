{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Define the path to the data folder\n",
    "data_folder = 'data_profiling_perf'\n",
    "\n",
    "data = {}\n",
    "pattern = re.compile(r'^\\s*([\\d,]+)\\s+([\\w\\.-]+).*$', re.MULTILINE)\n",
    "\n",
    "for f in os.listdir(data_folder):\n",
    "    if f.endswith('.log'):\n",
    "        program, threads, dataset = f.split('-')\n",
    "        threads = int(threads)\n",
    "        dataset = dataset.replace('.log', '')\n",
    "\n",
    "        if program not in data: data[program] = {}\n",
    "        if threads not in data[program]: data[program][threads] = {}\n",
    "\n",
    "        # Parse the file content\n",
    "        matches = []\n",
    "        with open(os.path.join(data_folder, f), 'r') as file:\n",
    "            matches = pattern.findall(file.read())\n",
    "\n",
    "        # Create a dataframe from the parsed data\n",
    "        _data = {}\n",
    "        for match in matches:\n",
    "            value, metric = match\n",
    "            _data[metric] = int(value.replace(',', ''))\n",
    "        # _data['cache-miss-ratio'] = _data['cache-misses'] / _data['cache-references']\n",
    "        _data['L1-miss-ratio'] = _data['L1-dcache-load-misses'] / _data['L1-dcache-loads']\n",
    "        _data['L2-miss-ratio'] = _data['l2_rqsts.demand_data_rd_miss'] / _data['l2_rqsts.all_demand_data_rd']\n",
    "        _data['L3-miss-ratio'] = _data['LLC-load-misses'] / _data['LLC-loads']\n",
    "        _data['L1-miss-rate'] = _data['L1-dcache-load-misses'] / _data['mem_inst_retired.all_loads']\n",
    "        _data['L2-miss-rate'] = _data['l2_rqsts.demand_data_rd_miss'] / _data['mem_inst_retired.all_loads']\n",
    "        _data['L3-miss-rate'] = _data['LLC-load-misses'] / _data['mem_inst_retired.all_loads']\n",
    "\n",
    "        data[program][threads][dataset] = _data\n",
    "    \n",
    "\n",
    "for program, threads_data in data.items():\n",
    "    print(program)\n",
    "    for threads, datasets in threads_data.items():\n",
    "        print(f'  {threads} threads')\n",
    "        for dataset, df in datasets.items():\n",
    "            print(f'    {dataset}')\n",
    "            print(df)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FONT_TITLE = 18\n",
    "FONT_AXES = 18\n",
    "FONT_TICKS = 14\n",
    "FONT_LEGEND = 14\n",
    "\n",
    "datasets = [\n",
    "    # 'Social_Network_1',\n",
    "    # 'Web_Graph_1',\n",
    "    # 'Collaboration_Network_1',\n",
    "    # 'Synthetic_Dense_1',\n",
    "    'Road_Network_1',\n",
    "    'Road_Network_2',\n",
    "    'kNN_Graph_1',\n",
    "    'Synthetic_Sparse_1',\n",
    "]\n",
    "\n",
    "programs = ['large', 'small', 'classic']\n",
    "\n",
    "for threads in [24, 32]:\n",
    "    for kind in ['rate', 'ratio']:\n",
    "        for metric in ['L1-miss', 'L2-miss', 'L3-miss']:\n",
    "            metric = metric + '-' + kind\n",
    "            # Extract cache miss ratios for each dataset and program\n",
    "            cache_miss_ratios = {program: [data[program][threads][dataset][metric] for dataset in datasets] for program in programs}\n",
    "\n",
    "            # Plot the cache miss ratios\n",
    "            x = np.arange(len(datasets))  # the label locations\n",
    "            width = 0.2  # the width of the bars\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "            for i, program in enumerate(programs):\n",
    "                ax.bar(x + i * width, cache_miss_ratios[program], width, label=program)\n",
    "\n",
    "            ax.set_ylabel(metric, fontsize=FONT_TICKS)\n",
    "            ax.set_title(f'{metric} for {threads} threads', fontsize=FONT_TITLE)\n",
    "            ax.set_xticks(x + width / len(programs))\n",
    "            ax.set_xticklabels(datasets, rotation=45, fontsize=FONT_TICKS-2)\n",
    "            ax.legend(loc='best', fontsize=FONT_LEGEND)\n",
    "            ax.grid(True, linestyle=':')\n",
    "\n",
    "            fig.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['classic', 'small', 'large']\n",
    "datasets = [\n",
    "    'Social_Network_1',\n",
    "    'Web_Graph_1',\n",
    "    'Collaboration_Network_1',\n",
    "    'Synthetic_Dense_1',\n",
    "    'Road_Network_1',\n",
    "    'Road_Network_2',\n",
    "    'kNN_Graph_1',\n",
    "    'Synthetic_Sparse_1',\n",
    "]\n",
    "escaped_datasets = [dataset.replace('_', ' ') for dataset in datasets]\n",
    "\n",
    "for threads in [24, 48, 96]:\n",
    "    # Initialize an empty dataframe to store the results\n",
    "    average_cache_misses = pd.DataFrame(index=escaped_datasets, columns=folders)\n",
    "\n",
    "    # Iterate over each folder and dataset to calculate the average cache misses\n",
    "    for folder in folders:\n",
    "        for dataset, escaped_dataset in zip(datasets, escaped_datasets):\n",
    "            df = data[folder][threads][dataset]['L2CACHE']\n",
    "            # Calculate the average cache misses\n",
    "            # print(f\"Folder: {folder} -- Dataset: {dataset}\")\n",
    "            # print(df[df['Metric'] == 'L2 miss ratio'].iloc[0, 1:].astype(float))\n",
    "            miss_ratios = df[df['Metric'] == 'L2 miss ratio'].iloc[0, 1:].astype(float)\n",
    "            min_cache_misses = miss_ratios.min()\n",
    "            max_cache_misses = miss_ratios.max()\n",
    "            avg_cache_misses = miss_ratios.mean()\n",
    "            # Store the result in the dataframe\n",
    "            average_cache_misses.loc[escaped_dataset, folder] = f'{int(min_cache_misses*100)}/{int(max_cache_misses*100)}/{int(avg_cache_misses*100)}'\n",
    "\n",
    "    # Display the resulting dataframe\n",
    "    print(f'====== {threads=} ======')\n",
    "    print(average_cache_misses)\n",
    "    print(average_cache_misses.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
