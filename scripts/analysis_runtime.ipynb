{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "import os\n",
    "# import numpy as np\n",
    "# from scipy.stats import chi2\n",
    "\n",
    "# Define a pattern to match the relevant data\n",
    "RE_IGNORE_OPTIONAL_LINE = r'(?:[^\\n]*)?'\n",
    "pattern = [\n",
    "    r'Running ([\\./\\w]+) on (\\w+)[^\\n]*',\n",
    "    RE_IGNORE_OPTIONAL_LINE,\n",
    "    RE_IGNORE_OPTIONAL_LINE,\n",
    "    r'Number of threads: (\\d+)',\n",
    "    r'Runtime: (\\d+\\.[\\d]+)'\n",
    "]\n",
    "pattern = r'\\n?'.join(pattern) # This ? may cause unexpected behavior\n",
    "print(f'Pattern: {pattern}')\n",
    "\n",
    "pattern_beamer = [\n",
    "    r'Running ([\\./\\w]+) on (\\w+)[^\\n]*',\n",
    "    RE_IGNORE_OPTIONAL_LINE,\n",
    "    RE_IGNORE_OPTIONAL_LINE,\n",
    "    RE_IGNORE_OPTIONAL_LINE,\n",
    "    RE_IGNORE_OPTIONAL_LINE,\n",
    "    r'Average Time: +(\\d+\\.[\\d]+)'\n",
    "]\n",
    "pattern_beamer = r'\\n?'.join(pattern_beamer) # This ? may cause unexpected behavior\n",
    "print(f'Pattern reference: {pattern_beamer}')\n",
    "\n",
    "# List all files in the 'data_runtime' directory\n",
    "all_files = os.listdir('data_runtime')\n",
    "\n",
    "# Filter files that start with 'runtime_'\n",
    "runtime_files = [f for f in all_files if f.startswith('runtime_')]\n",
    "\n",
    "runtimes = {}\n",
    "\n",
    "for runtime_file in runtime_files:\n",
    "    print(f'Parsing {runtime_file}...')\n",
    "    with open(f'data_runtime/{runtime_file}', 'r') as file:\n",
    "        file_format = file.read()\n",
    "\n",
    "    # Find all matches in the string\n",
    "    matches = re.findall(pattern if 'beamer' not in runtime_file else pattern_beamer, file_format)\n",
    "    print(f'Found {len(matches)} matches')\n",
    "    program = runtime_file[len('runtime_'):-4]\n",
    "    program = ''.join([i for i in program if not i.isdigit()])\n",
    "    \n",
    "    # Convert matches to a list of dictionaries\n",
    "    for match in matches:\n",
    "        if 'beamer' in runtime_file:\n",
    "            binary = match[0]\n",
    "            dataset = match[1]\n",
    "            threads = 32\n",
    "            runtime = float(match[2])\n",
    "        else:\n",
    "            binary = match[0]\n",
    "            dataset = match[1]\n",
    "            threads = int(match[2])\n",
    "            runtime = float(match[3])\n",
    "\n",
    "        # Init dictionary\n",
    "        if runtimes.get(program) == None:\n",
    "            runtimes[program] = {}\n",
    "        if runtimes[program].get(threads) == None:\n",
    "            runtimes[program][threads] = {}\n",
    "        if runtimes[program][threads].get(dataset) == None:\n",
    "            runtimes[program][threads][dataset] = []\n",
    "\n",
    "        runtimes[program][threads][dataset].append({'binary': binary, 'threads': threads, 'runtime': runtime})\n",
    "\n",
    "# pprint.pprint(runtimes)\n",
    "\n",
    "# for program, threads_l in runtimes.items():\n",
    "#     for threads, dataset in threads_l.items():\n",
    "#         for dataset, entries in dataset.items():\n",
    "#             runtime_values = [float(entry['runtime']) for entry in entries]\n",
    "#             # print(f'{program} on {dataset}: {runtime_values}')\n",
    "            \n",
    "#             # Expected variance (threshold for acceptable noise)\n",
    "#             expected_variance = 0.1\n",
    "\n",
    "#             # Sample variance\n",
    "#             sample_variance = np.var(runtime_values, ddof=1)\n",
    "\n",
    "#             # Number of samples\n",
    "#             n = len(runtime_values)\n",
    "\n",
    "#             # Chi-square statistic\n",
    "#             chi2_stat = (n - 1) * sample_variance / expected_variance\n",
    "\n",
    "#             # p-value (two-tailed test)\n",
    "#             p_value = 2 * min(chi2.cdf(chi2_stat, n - 1), 1 - chi2.cdf(chi2_stat, n - 1))\n",
    "\n",
    "#             # print(f\"Sample Variance: {sample_variance}\")\n",
    "#             # print(f\"Chi-Square Statistic: {chi2_stat}\")\n",
    "#             # print(f\"P-Value: {p_value}\")\n",
    "\n",
    "#             # Interpretation\n",
    "#             alpha = 0.05  # Significance level\n",
    "#             if p_value < alpha:\n",
    "#                 print(\"The variance is significantly different from the expected value.\")\n",
    "#             else:\n",
    "#                 print(\"The variance is NOT significantly different from the expected value.\")\n",
    "\n",
    "\n",
    "average_runtimes = {}\n",
    "for program, threads_l in runtimes.items():\n",
    "    if average_runtimes.get(program) is None:\n",
    "        average_runtimes[program] = {}\n",
    "    for threads, datasets in threads_l.items():\n",
    "        if average_runtimes[program].get(threads) is None:\n",
    "            average_runtimes[program][threads] = {}\n",
    "        for dataset, entries in datasets.items():\n",
    "            total_runtime = sum(float(entry['runtime']) for entry in entries)\n",
    "            average_runtime = total_runtime / len(entries)\n",
    "            average_runtimes[program][threads][dataset] = average_runtime\n",
    "\n",
    "sequential_naive = None\n",
    "if 'sequential_naive' in average_runtimes:\n",
    "    sequential_naive = average_runtimes['sequential_naive'][list(average_runtimes['sequential_naive'].keys())[0]]\n",
    "    del average_runtimes['sequential_naive']\n",
    "\n",
    "pprint.pprint(average_runtimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate plots on runtime and speedups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FONT_TITLE = 18\n",
    "FONT_AXES = 18\n",
    "FONT_TICKS = 14\n",
    "FONT_LEGEND = 14\n",
    "dataset_sizes = {\n",
    "    'Social_Network_1':         (4799030,83971060),\n",
    "    'Web_Graph_1':              (6558851,294259270),\n",
    "    'Collaboration_Network_1':  (1058365,110391514),\n",
    "    'Synthetic_Dense_1':        (9899865,980075384),\n",
    "    'Road_Network_1':           (21872120,58216498),\n",
    "    'kNN_Graph_1':              (24627858,154302284),\n",
    "    'Synthetic_Sparse_1':       (9899865,39202750),\n",
    "    'Road_Network_2':           (86081964,215900378),\n",
    "}\n",
    "def human_readable_size(size):\n",
    "    if size >= 1e9:\n",
    "        return f'{size / 1e9:.1f} B'\n",
    "    else:\n",
    "        return f'{size / 1e6:.1f} M'\n",
    "for dataset, (nodes, edges) in dataset_sizes.items():\n",
    "    print(f'{dataset:<30}: {human_readable_size(nodes):<5} nodes, {human_readable_size(edges)} edges')\n",
    "\n",
    "dataset_category = {\n",
    "    'Social_Network_1':         'small',\n",
    "    'Web_Graph_1':              'small',\n",
    "    'Collaboration_Network_1':  'small',\n",
    "    'Synthetic_Dense_1':        'small',\n",
    "    'Road_Network_1':           'large',\n",
    "    'kNN_Graph_1':              'large',\n",
    "    'Synthetic_Sparse_1':       'large',\n",
    "    'Road_Network_2':           'large',\n",
    "}\n",
    "category_colors = {\n",
    "    'small': 'blue',\n",
    "    'large': 'green',\n",
    "    'verylarge': 'green',\n",
    "}\n",
    "datasets = list(dataset_category.keys())\n",
    "BASELINE_PROGRAM = 'sbeamer_four_twfour' # sbeamer_four_twfour sbeamer_fiftn_eigtn\n",
    "programs = [\n",
    "    # 'small96',\n",
    "    # 'large96',\n",
    "    # 'verylarge96',\n",
    "    # 'auto96',\n",
    "\n",
    "    # 'small24',\n",
    "    # 'large24',\n",
    "    # 'verylarge24',\n",
    "    # 'auto24',\n",
    "\n",
    "    BASELINE_PROGRAM,\n",
    "    'small',\n",
    "    'large',\n",
    "]\n",
    "\n",
    "PROGRAM_LABELS = {\n",
    "    'small': 'Bitmap',\n",
    "    'large': 'MergedCSR',\n",
    "}\n",
    "\n",
    "# Calculate speedups\n",
    "speedups = {}\n",
    "for program in programs:\n",
    "    program_threads = average_runtimes.get(program, {})\n",
    "    speedups[program] = {}\n",
    "    for threads, program_datasets in program_threads.items():\n",
    "        speedups[program][threads] = {}\n",
    "        for dataset, runtime in program_datasets.items():\n",
    "            if threads in average_runtimes[BASELINE_PROGRAM]:\n",
    "                if dataset in average_runtimes[BASELINE_PROGRAM][threads]:\n",
    "                    speedups[program][threads][dataset] = average_runtimes[BASELINE_PROGRAM][threads][dataset] / runtime\n",
    "            else:\n",
    "                speedups[program][threads][dataset] = 0\n",
    "\n",
    "eps = {}\n",
    "for program in programs:\n",
    "    program_threads = average_runtimes.get(program, {})\n",
    "    eps[program] = {}\n",
    "    for threads, program_datasets in program_threads.items():\n",
    "        eps[program][threads] = {}\n",
    "        for dataset, runtime in program_datasets.items():\n",
    "            if threads in average_runtimes[program]:\n",
    "                if dataset in average_runtimes[program][threads]:\n",
    "                    eps[program][threads][dataset] = dataset_sizes[dataset][1] / runtime\n",
    "            else:\n",
    "                eps[program][threads][dataset] = 0\n",
    "\n",
    "if sequential_naive is not None:\n",
    "    speedups_naive = {}\n",
    "    for program in programs:\n",
    "        program_threads = average_runtimes.get(program, {})\n",
    "        speedups_naive[program] = {}\n",
    "        for threads, program_datasets in program_threads.items():\n",
    "            speedups_naive[program][threads] = {}\n",
    "            for dataset, runtime in program_datasets.items():\n",
    "                if dataset in average_runtimes[program][threads]:\n",
    "                    speedups_naive[program][threads][dataset] = sequential_naive[dataset] / runtime\n",
    "\n",
    "speedups_scalability = {}\n",
    "for program in programs:\n",
    "    if program == BASELINE_PROGRAM:\n",
    "        continue\n",
    "    program_threads = average_runtimes.get(program, {})\n",
    "    speedups_scalability[program] = {}\n",
    "    for threads, program_datasets in program_threads.items():\n",
    "        speedups_scalability[program][threads] = {}\n",
    "        for dataset, runtime in program_datasets.items():\n",
    "            ref_runtime = average_runtimes[program][1].get(dataset)\n",
    "            # if ref_runtime is None:\n",
    "            #     print(f'WARNING: Reference runtime for {program} on {dataset} with 1 thread is None and has been set to 60s')\n",
    "            speedups_scalability[program][threads][dataset] = (60 if ref_runtime is None else ref_runtime) / runtime\n",
    "\n",
    "print(\"===== SPEEDUPS =====\")\n",
    "pprint.pprint(speedups)\n",
    "print(\"\\n===== SPEEDUPS SCALABILITY =====\")\n",
    "pprint.pprint(speedups_scalability)\n",
    "print(\"\\n===== Edges/s =====\")\n",
    "pprint.pprint(eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot speedups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_datasets = [d for d in datasets if dataset_category[d] == 'small']\n",
    "large_datasets = [d for d in datasets if dataset_category[d] == 'large']\n",
    "\n",
    "FONT_TITLE = 18\n",
    "FONT_AXES = 18\n",
    "FONT_LEGEND = 14\n",
    "BAR_WIDTH = 0.3\n",
    "\n",
    "# _threads = sorted(average_runtimes[BASELINE_PROGRAM].keys())\n",
    "_threads = [32]\n",
    "\n",
    "for threads in _threads:\n",
    "    max_eps = -1\n",
    "    # Plot speedups for small datasets\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    for i, (program, program_speedups) in enumerate(speedups.items()):\n",
    "        if program != BASELINE_PROGRAM:\n",
    "            small_datasets = [d for d in datasets if dataset_category[d] == 'small']\n",
    "            program_speedups = program_speedups[threads]\n",
    "            small_speedups = [program_speedups.get(dataset, np.nan) for dataset in small_datasets]\n",
    "            bars = ax.bar(np.arange(len(small_datasets)) + i * BAR_WIDTH, small_speedups, BAR_WIDTH, label=PROGRAM_LABELS.get(program, program))\n",
    "            for bar, speedup in zip(bars, small_speedups):\n",
    "                if np.isnan(speedup):\n",
    "                    ax.text(bar.get_x() + bar.get_width() / 4, 0, 'x')\n",
    "                else:\n",
    "                    max_eps = max(max_eps, speedup)\n",
    "    max_eps = int(max_eps) + 2\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    # ax.set_xlabel('Small Datasets')\n",
    "    # ax.set_ylabel('Speedup', fontsize=FONT_AXES)\n",
    "    speedup_ticks = np.arange(max_eps, step=0.25)\n",
    "    ax.plot(range(5), [1] * int(5), color='black', linestyle=':')\n",
    "    ax.set_title(f'Speedups ({threads} threads)', fontsize=FONT_TITLE)\n",
    "    ax.set_yticks(speedup_ticks)\n",
    "    ax.set_yticklabels([f'{i}x' for i in speedup_ticks], fontsize=FONT_TICKS)\n",
    "    ax.set_xticks(np.arange(len(small_datasets)) + 1.5 * BAR_WIDTH)\n",
    "    ax.set_xticklabels(small_datasets, rotation=45, ha='right', fontsize=FONT_TICKS-2)\n",
    "    # for tick, dataset in zip(ax.get_xticklabels(), small_datasets):\n",
    "    #     tick.set_color(category_colors[dataset_category[dataset]])\n",
    "    ax.legend(loc='upper left', fontsize=FONT_LEGEND)\n",
    "    ax.grid(True, linestyle=':')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    max_eps = -1\n",
    "    # Plot speedups for large datasets\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    for i, (program, program_speedups) in enumerate(speedups.items()):\n",
    "        if program != BASELINE_PROGRAM:\n",
    "            large_datasets = [d for d in datasets if dataset_category[d] == 'large']\n",
    "            program_speedups = program_speedups[threads]\n",
    "            large_speedups = [program_speedups.get(dataset, np.nan) for dataset in large_datasets]\n",
    "            bars = ax.bar(np.arange(len(large_datasets)) + i * BAR_WIDTH, large_speedups, BAR_WIDTH, label=PROGRAM_LABELS.get(program, program))\n",
    "            for bar, speedup in zip(bars, large_speedups):\n",
    "                if np.isnan(speedup):\n",
    "                    ax.text(bar.get_x() + bar.get_width() / 4, 0, 'x')\n",
    "                else:\n",
    "                    max_eps = max(max_eps, speedup)\n",
    "    max_eps = int(max_eps) + 2\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    # ax.set_xlabel('Large Datasets')\n",
    "    # ax.set_ylabel('Speedup', fontsize=FONT_AXES)\n",
    "    speedup_ticks = np.arange(max_eps, step=0.25)\n",
    "    ax.plot(range(5), [1] * int(5), color='black', linestyle=':')\n",
    "    ax.set_title(f'Speedups ({threads} threads)', fontsize=FONT_TITLE)\n",
    "    ax.set_yticks(speedup_ticks)\n",
    "    ax.set_yticklabels([f'{i:.2f}x' for i in speedup_ticks], fontsize=FONT_TICKS)\n",
    "    ax.set_xticks(np.arange(len(large_datasets)) + 1.5 * BAR_WIDTH)\n",
    "    ax.set_xticklabels(large_datasets, rotation=45, ha='right', fontsize=FONT_TICKS-2)\n",
    "    # for tick, dataset in zip(ax.get_xticklabels(), large_datasets):\n",
    "    #     tick.set_color(category_colors[dataset_category[dataset]])\n",
    "    ax.legend(loc='upper left', fontsize=FONT_LEGEND)\n",
    "    ax.grid(True, linestyle=':')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Edges/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "_threads = [32]\n",
    "\n",
    "for threads in _threads:\n",
    "    # Create a DataFrame for eps\n",
    "    eps_data = []\n",
    "    for program, threads_data in eps.items():\n",
    "        threads_data = threads_data[threads]\n",
    "        for dataset, value in threads_data.items():\n",
    "            eps_data.append([program, threads, dataset, value])\n",
    "\n",
    "    eps_df = pd.DataFrame(eps_data, columns=['Program', 'Threads', 'Dataset', 'Edges/s'])\n",
    "    eps_df_pivot = eps_df.pivot_table(index=['Dataset', 'Threads'], columns='Program', values='Edges/s')\n",
    "    # print(eps_df_pivot)\n",
    "\n",
    "    def format_number(x):\n",
    "        if x >= 1e9:\n",
    "            return f'{x / 1e9:.1f}B'\n",
    "        elif x >= 1e6:\n",
    "            return f'{x / 1e6:.1f}M'\n",
    "        else:\n",
    "            return f'{x:.1f}'\n",
    "    formatted_eps_df_pivot = eps_df_pivot.map(format_number)\n",
    "    print(formatted_eps_df_pivot)\n",
    "    print(formatted_eps_df_pivot.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot speedups wrt to naive serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _threads = sorted(average_runtimes[BASELINE_PROGRAM].keys())\n",
    "_threads = [32]\n",
    "\n",
    "if sequential_naive is not None and speedups_naive is not None:\n",
    "    for threads in _threads:\n",
    "        max_eps = -1\n",
    "        # Plot speedups for small datasets\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        for i, (program, program_speedups) in enumerate(speedups_naive.items()):\n",
    "            if program != BASELINE_PROGRAM:\n",
    "                small_datasets = [d for d in datasets if dataset_category[d] == 'small']\n",
    "                program_speedups = program_speedups[threads]\n",
    "                small_speedups = [program_speedups.get(dataset, np.nan) for dataset in small_datasets]\n",
    "                bars = ax.bar(np.arange(len(small_datasets)) + i * BAR_WIDTH, small_speedups, BAR_WIDTH, label=program)\n",
    "                for bar, speedup in zip(bars, small_speedups):\n",
    "                    if np.isnan(speedup):\n",
    "                        ax.text(bar.get_x() + bar.get_width() / 4, 0, 'x')\n",
    "                    else:\n",
    "                        max_eps = max(max_eps, speedup)\n",
    "        max_eps = int(max_eps) + 2\n",
    "\n",
    "        # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "        # ax.set_xlabel('Small Datasets')\n",
    "        # ax.set_ylabel('Speedup', fontsize=FONT_AXES)\n",
    "        ax.set_title(f'Speedups Using {threads} Threads', fontsize=FONT_TITLE)\n",
    "        # ax.set_yticks(np.arange(max_speedup))\n",
    "        # ax.set_yticklabels([f'{i}x' for i in range(max_speedup)], fontsize=FONT_TICKS)\n",
    "        ax.set_xticks(np.arange(len(small_datasets)) + 1.5 * BAR_WIDTH)\n",
    "        ax.set_xticklabels(small_datasets, rotation=45, ha='right', fontsize=FONT_TICKS-2)\n",
    "        # for tick, dataset in zip(ax.get_xticklabels(), small_datasets):\n",
    "        #     tick.set_color(category_colors[dataset_category[dataset]])\n",
    "        ax.legend(loc='upper left', fontsize=FONT_LEGEND)\n",
    "        ax.grid(True, linestyle=':')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        max_eps = -1\n",
    "        # Plot speedups for large datasets\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        for i, (program, program_speedups) in enumerate(speedups_naive.items()):\n",
    "            if program != BASELINE_PROGRAM:\n",
    "                large_datasets = [d for d in datasets if dataset_category[d] == 'large']\n",
    "                program_speedups = program_speedups[threads]\n",
    "                large_speedups = [program_speedups.get(dataset, np.nan) for dataset in large_datasets]\n",
    "                bars = ax.bar(np.arange(len(large_datasets)) + i * BAR_WIDTH, large_speedups, BAR_WIDTH, label=program)\n",
    "                for bar, speedup in zip(bars, large_speedups):\n",
    "                    if np.isnan(speedup):\n",
    "                        ax.text(bar.get_x() + bar.get_width() / 4, 0, 'x')\n",
    "                    else:\n",
    "                        max_eps = max(max_eps, speedup)\n",
    "        max_eps = int(max_eps) + 2\n",
    "\n",
    "        # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "        # ax.set_xlabel('Large Datasets')\n",
    "        # ax.set_ylabel('Speedup', fontsize=FONT_AXES)\n",
    "        ax.set_title(f'Speedups Using {threads} Threads', fontsize=FONT_TITLE)\n",
    "        # ax.set_yticks(np.arange(max_speedup))\n",
    "        # ax.set_yticklabels([f'{i}x' for i in range(max_speedup)], fontsize=FONT_TICKS)\n",
    "        ax.set_xticks(np.arange(len(large_datasets)) + 1.5 * BAR_WIDTH)\n",
    "        ax.set_xticklabels(large_datasets, rotation=45, ha='right', fontsize=FONT_TICKS-2)\n",
    "        # for tick, dataset in zip(ax.get_xticklabels(), large_datasets):\n",
    "        #     tick.set_color(category_colors[dataset_category[dataset]])\n",
    "        ax.legend(loc='upper left', fontsize=FONT_LEGEND)\n",
    "        ax.grid(True, linestyle=':')\n",
    "        fig.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "\n",
    "small_datasets = [d for d in datasets if dataset_category[d] == 'small']\n",
    "large_datasets = [d for d in datasets if dataset_category[d] == 'large']\n",
    "\n",
    "geometric_means = {}\n",
    "for program, threads_data in eps.items():\n",
    "    geometric_means[program] = {'small': {}, 'large': {}}\n",
    "    for threads, datasets_data in threads_data.items():\n",
    "        small_values = [value for dataset, value in datasets_data.items() if dataset in small_datasets and value > 0]\n",
    "        large_values = [value for dataset, value in datasets_data.items() if dataset in large_datasets and value > 0]\n",
    "        \n",
    "        if small_values:\n",
    "            geometric_means[program]['small'][threads] = gmean(small_values)\n",
    "        else:\n",
    "            geometric_means[program]['small'][threads] = np.nan\n",
    "        \n",
    "        if large_values:\n",
    "            geometric_means[program]['large'][threads] = gmean(large_values)\n",
    "        else:\n",
    "            geometric_means[program]['large'][threads] = np.nan\n",
    "\n",
    "pprint.pprint(geometric_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threads in [32]:\n",
    "    print(f'SMALL {threads} threads')\n",
    "    print(f'\\t{\"Beamer\":<10} {human_readable_size(geometric_means[\"sbeamer_four_twfour\"][\"small\"][threads])}edges/s')\n",
    "    print(f'\\t{\"Small\":<10} {human_readable_size(geometric_means[\"small\"][\"small\"][threads])}edges/s')\n",
    "    print(f'\\t{\"Ratio\":<10} {geometric_means[\"small\"][\"small\"][threads] / geometric_means[\"sbeamer_four_twfour\"][\"small\"][threads]:.2f}')\n",
    "    print(f'LARGE {threads} threads')\n",
    "    print(f'\\t{\"Beamer\":<10} {human_readable_size(geometric_means[\"sbeamer_four_twfour\"][\"large\"][threads])}edges/s')\n",
    "    print(f'\\t{\"Large\":<10} {human_readable_size(geometric_means[\"large\"][\"large\"][threads])}edges/s')\n",
    "    print(f'\\t{\"Ratio\":<10} {geometric_means[\"large\"][\"large\"][threads] / geometric_means[\"sbeamer_four_twfour\"][\"large\"][threads]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate scalability plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_TITLE = 18\n",
    "FONT_AXES = 18\n",
    "FONT_TICKS = 14\n",
    "FONT_LEGEND = 14\n",
    "\n",
    "for program in programs:\n",
    "    if program == BASELINE_PROGRAM:\n",
    "        continue\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    thread_counts = sorted(speedups_scalability[program].keys())\n",
    "    for dataset in datasets:\n",
    "        if program == dataset_category[dataset]:\n",
    "            speedup_values = [speedups_scalability[program][threads].get(dataset, np.nan) for threads in thread_counts]\n",
    "            ax.plot(thread_counts, speedup_values, marker='o', label=dataset)\n",
    "    \n",
    "    # Ideal speedup\n",
    "    ax.plot(thread_counts, thread_counts, '--', color='gray', label='Ideal Speedup')\n",
    "\n",
    "    ax.set_xlabel('Number of Threads', fontsize=FONT_AXES)\n",
    "    ax.set_ylabel('Speedup (w.r.t. 1 thread)', fontsize=FONT_AXES)\n",
    "    ax.set_title(f'Scaling on graphs with {\"large\" if program==\"small\" else \"small\"} frontiers', fontsize=FONT_TITLE)\n",
    "    ax.set_xticks(thread_counts)\n",
    "    ax.set_xticklabels(thread_counts, fontsize=FONT_TICKS)\n",
    "    ax.set_yticks(thread_counts)\n",
    "    ax.set_yticklabels(thread_counts, fontsize=FONT_TICKS)\n",
    "    # ax.set_xlim((0,8))\n",
    "    ax.set_ylim((0,32))\n",
    "    ax.legend(loc='best', fontsize=FONT_LEGEND)\n",
    "    ax.grid(True, linestyle=':')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
