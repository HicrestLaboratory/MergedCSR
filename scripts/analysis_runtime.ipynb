{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Define a pattern to match the relevant data\n",
    "RE_IGNORE_OPTIONAL_LINE = r'(?:[^\\n]*)?'\n",
    "pattern = [\n",
    "    r'Running ([/\\w]+) on (\\w+)[^\\n]*',\n",
    "    RE_IGNORE_OPTIONAL_LINE,\n",
    "    RE_IGNORE_OPTIONAL_LINE,\n",
    "    r'Number of threads: (\\d+)',\n",
    "    r'Runtime: (\\d+\\.[\\d]+)'\n",
    "]\n",
    "pattern = r'\\n?'.join(pattern) # This ? may cause unexpected behavior\n",
    "print(f'Pattern: {pattern}')\n",
    "\n",
    "# List all files in the 'data_runtime' directory\n",
    "all_files = os.listdir('data_runtime')\n",
    "\n",
    "# Filter files that start with 'runtime_'\n",
    "runtime_files = [f for f in all_files if f.startswith('runtime_')]\n",
    "\n",
    "runtimes = {}\n",
    "\n",
    "for runtime_file in runtime_files:\n",
    "    print(f'Parsing {runtime_file}...')\n",
    "    with open(f'data_runtime/{runtime_file}', 'r') as file:\n",
    "        file_format = file.read()\n",
    "\n",
    "    # Find all matches in the string\n",
    "    matches = re.findall(pattern, file_format)\n",
    "    print(f'Found {len(matches)} matches')\n",
    "    program = runtime_file[len('runtime_'):-4]\n",
    "    \n",
    "    # Convert matches to a list of dictionaries\n",
    "    for match in matches:\n",
    "        dataset = match[1]\n",
    "        if runtimes.get(program) == None:\n",
    "            runtimes[program] = {}\n",
    "        if runtimes[program].get(dataset) == None:\n",
    "            runtimes[program][dataset] = []\n",
    "        runtimes[program][dataset].append({'binary': match[0], 'threads': int(match[2]), 'runtime': match[3]})\n",
    "\n",
    "# pprint.pprint(runtimes)\n",
    "\n",
    "for program, datasets in runtimes.items():\n",
    "    for dataset, entries in datasets.items():\n",
    "        runtime_values = [float(entry['runtime']) for entry in entries]\n",
    "        # print(f'{program} on {dataset}: {runtime_values}')\n",
    "        \n",
    "        # Expected variance (threshold for acceptable noise)\n",
    "        expected_variance = 0.1  # Adjust based on your requirements\n",
    "\n",
    "        # Sample variance\n",
    "        sample_variance = np.var(runtime_values, ddof=1)\n",
    "\n",
    "        # Number of samples\n",
    "        n = len(runtime_values)\n",
    "\n",
    "        # Chi-square statistic\n",
    "        chi2_stat = (n - 1) * sample_variance / expected_variance\n",
    "\n",
    "        # p-value (two-tailed test)\n",
    "        p_value = 2 * min(chi2.cdf(chi2_stat, n - 1), 1 - chi2.cdf(chi2_stat, n - 1))\n",
    "\n",
    "        # print(f\"Sample Variance: {sample_variance}\")\n",
    "        # print(f\"Chi-Square Statistic: {chi2_stat}\")\n",
    "        # print(f\"P-Value: {p_value}\")\n",
    "\n",
    "        # Interpretation\n",
    "        alpha = 0.05  # Significance level\n",
    "        if p_value < alpha:\n",
    "            print(\"The variance is significantly different from the expected value.\")\n",
    "        else:\n",
    "            print(\"The variance is NOT significantly different from the expected value.\")\n",
    "\n",
    "\n",
    "average_runtimes = {}\n",
    "for program, datasets in runtimes.items():\n",
    "    if program not in average_runtimes:\n",
    "        average_runtimes[program] = {}\n",
    "    for dataset, entries in datasets.items():\n",
    "        total_runtime = sum(float(entry['runtime']) for entry in entries)\n",
    "        average_runtime = total_runtime / len(entries)\n",
    "        average_runtimes[program][dataset] = average_runtime\n",
    "\n",
    "pprint.pprint(average_runtimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate plots on runtime and speedups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_category = {\n",
    "    'Social_Network_1':         'small',\n",
    "    'Web_Graph_1':              'small',\n",
    "    'Collaboration_Network_1':  'small',\n",
    "    'Synthetic_Dense_1':        'small',\n",
    "    'Road_Network_1':           'large',\n",
    "    'kNN_Graph_1':              'large',\n",
    "    'Synthetic_Sparse_1':       'large',\n",
    "    'Road_Network_2':           'verylarge',\n",
    "}\n",
    "category_colors = {\n",
    "    'small': 'blue',\n",
    "    'large': 'green',\n",
    "    'verylarge': 'red',\n",
    "}\n",
    "datasets = list(dataset_category.keys())\n",
    "programs = [\n",
    "    'small96',\n",
    "    'large96',\n",
    "    'verylarge96',\n",
    "    'auto96',\n",
    "\n",
    "    # 'small24',\n",
    "    # 'large24',\n",
    "    # 'verylarge24',\n",
    "    # 'auto24',\n",
    "]\n",
    "\n",
    "# Calculate speedups\n",
    "speedups = {}\n",
    "for program in programs:\n",
    "    program_datasets = average_runtimes.get(program, {})\n",
    "    speedups[program] = {}\n",
    "    for dataset, runtime in program_datasets.items():\n",
    "        if dataset in average_runtimes['reference']:\n",
    "            speedups[program][dataset] = average_runtimes['reference'][dataset] / runtime\n",
    "\n",
    "pprint.pprint(speedups)\n",
    "\n",
    "# Prepare data for plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "BAR_WIDTH = 0.1\n",
    "\n",
    "# Plot speedups\n",
    "for i, (program, program_speedups) in enumerate(speedups.items()):\n",
    "    if program != 'reference':\n",
    "        program_speedups = [program_speedups.get(dataset, np.nan) for dataset in datasets]\n",
    "        bars = ax.bar(np.arange(len(datasets)) + i * BAR_WIDTH, program_speedups, BAR_WIDTH, label=program)\n",
    "        for bar, speedup in zip(bars, program_speedups):\n",
    "            if np.isnan(speedup):\n",
    "                ax.text(bar.get_x() + bar.get_width() / 4, 0, 'x')\n",
    "                \n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Datasets')\n",
    "ax.set_ylabel('Speedup (Reference / Other)')\n",
    "ax.set_title('Speedups by Dataset')\n",
    "ax.set_yticks(np.arange(80))\n",
    "ax.set_yticklabels([f'{i}x' for i in range(80)])\n",
    "ax.set_xticks(np.arange(len(datasets)) + BAR_WIDTH * (len(speedups) - 1) / 2)\n",
    "ax.set_xticklabels(datasets, rotation=45, ha='right')\n",
    "for tick, dataset in zip(ax.get_xticklabels(), datasets):\n",
    "    tick.set_color(category_colors[dataset_category[dataset]])\n",
    "ax.legend(loc='best')\n",
    "ax.grid()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
